{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import datefinder\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class HorizonParser():\n",
    "    \n",
    "    def __init__(self, dmp_title, dmp_description, dmp_created, dmp_modified, dmp_id, pi_name, pi_mail, pi_orcid):\n",
    "        self.setup_dmp(dmp_title, dmp_description, dmp_created, dmp_modified, dmp_id, pi_name, pi_mail, pi_orcid)\n",
    "    \n",
    "    def setup_dmp(self, dmp_title, dmp_description, dmp_created, dmp_modified, dmp_id, pi_name, pi_mail, pi_orcid):\n",
    "        self.dmp = {\n",
    "            \"dmp\":{\n",
    "                \"title\": dmp_title,\n",
    "                \"description\":\"Abstract::\"+dmp_description,\n",
    "                \"created\":dmp_created,\n",
    "                \"modified\":dmp_modified,\n",
    "                \"dmp_id\": {\n",
    "                    \"dmp_id\": dmp_id,\n",
    "                    \"dmp_id_type\": \"HTTP-DOI\"\n",
    "                },\n",
    "                \"contact\":{\n",
    "                    \"name\": pi_name,\n",
    "                    \"mail\": pi_mail,\n",
    "                    \"contact_id\": {\n",
    "                        \"contact_id\": pi_orcid,\n",
    "                        \"contact_id_type\": \"HTTP-ORCID\"\n",
    "                    }\n",
    "                },\n",
    "                \"project\": {}\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def __split_text_based_on_title(self, text):\n",
    "        rep = {}\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            title = ds[\"title\"].lower()\n",
    "            rep[title]=\";\"+title\n",
    "\n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text.lower()).split(\";\")\n",
    "        return text\n",
    "    \n",
    "    def parse_question_1_1(self, text):\n",
    "        if \"description\" in self.dmp[\"dmp\"][\"project\"]:\n",
    "            text=\";State the purpose of the data collection/generation::\"+text\n",
    "            self.dmp[\"dmp\"][\"project\"][\"description\"] += text\n",
    "        else:\n",
    "            text=\"State the purpose of the data collection/generation::\"+text\n",
    "            self.dmp[\"dmp\"][\"project\"][\"description\"] = text\n",
    "        return text\n",
    "    \n",
    "    def parse_question_1_2(self, text):\n",
    "        if \"description\" in self.dmp[\"dmp\"]:\n",
    "            text=\";Explain the relation to the objectives of the project::\"+text\n",
    "            self.dmp[\"dmp\"][\"description\"] += text\n",
    "        else:\n",
    "            text=\"Explain the relation to the objectives of the project::\"+text\n",
    "            self.dmp[\"dmp\"][\"description\"] = text\n",
    "        return text\n",
    "    \n",
    "    def parse_question_1_3(self, text):\n",
    "        rep = {\"Title:\": \";Title:\", \"Description:\": \";Description:\",\"Type:\": \";Type:\",\"Format:\": \";Format:\", \"Source:\":\";Source:\"} # define desired replacements here\n",
    "\n",
    "        rep_lower = {}\n",
    "        for k, v in rep.items():\n",
    "            rep_lower[k.lower()]=v\n",
    "        rep.update(rep_lower)    \n",
    "\n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)\n",
    "\n",
    "        datasets = []\n",
    "        current_dataset = None\n",
    "        current_format = None\n",
    "        for line in text.split(\";\"):\n",
    "            line = line.replace(\"\\n\",\"\")\n",
    "            if line.startswith(\"Title:\"):\n",
    "\n",
    "                line = line[7:] if line[6:].startswith(\" \") else line[6:]\n",
    "\n",
    "                if current_dataset != None:\n",
    "                    if \"distribution\" not in current_dataset:\n",
    "                        current_dataset[\"distribution\"] = []\n",
    "                        current_dataset[\"distribution\"].append({\"title\":\"Project\"})\n",
    "                    else:\n",
    "                        if current_format != None:\n",
    "                            for ds in current_dataset[\"distribution\"]:\n",
    "                                ds[\"format\"] = current_format\n",
    "                            current_format = None\n",
    "                    current_dataset[\"metadata\"] = []\n",
    "                    current_dataset[\"technical_resource\"] = []\n",
    "                    datasets.append(current_dataset)\n",
    "                current_dataset = {\"title\":line}\n",
    "\n",
    "            if line.startswith(\"Description:\"):\n",
    "                if current_dataset != None:\n",
    "                    line = line[13:] if line[12:].startswith(\" \") else line[12:]\n",
    "                    current_dataset[\"description\"]=line\n",
    "\n",
    "            if line.startswith(\"Type:\"):\n",
    "                if current_dataset != None:\n",
    "                    line = line[6:] if line[5:].startswith(\" \") else line[5:]\n",
    "                    current_dataset[\"type\"]=line\n",
    "\n",
    "            if line.startswith(\"Format:\"):\n",
    "                if current_dataset != None:\n",
    "                    line = line[8:] if line[7:].startswith(\" \") else line[7:]\n",
    "                    current_format = line\n",
    "\n",
    "            if line.startswith(\"Source:\"):\n",
    "                if current_dataset != None:\n",
    "                    line = line[8:] if line[7:].startswith(\" \") else line[7:]   \n",
    "                    if line.lower() == \"input\":\n",
    "                        current_dataset[\"distribution\"] = []\n",
    "                        current_dataset[\"distribution\"].append({\"title\":\"Origin\"})\n",
    "                        current_dataset[\"distribution\"].append({\"title\":\"Project\"})\n",
    "                    elif line.lower() == \"produced\":\n",
    "                        current_dataset[\"distribution\"] = []\n",
    "                        current_dataset[\"distribution\"].append({\"title\":\"Project\"})\n",
    "\n",
    "        if current_dataset != None:\n",
    "            if \"distribution\" not in current_dataset:\n",
    "                current_dataset[\"distribution\"] = []\n",
    "                current_dataset[\"distribution\"].append({\"title\":\"Project\"})\n",
    "            else:\n",
    "                if current_format != None:\n",
    "                    for ds in current_dataset[\"distribution\"]:\n",
    "                        ds[\"format\"] = current_format\n",
    "                    current_format = None\n",
    "            current_dataset[\"metadata\"] = []\n",
    "            current_dataset[\"technical_resource\"] = []\n",
    "            datasets.append(current_dataset)\n",
    "        \n",
    "        self.dmp[\"dmp\"][\"dataset\"]=datasets\n",
    "        return datasets\n",
    "    \n",
    "    def parse_question_1_4(self, text):\n",
    "        ret_val = {}\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            if ds[\"title\"].lower() in text.lower():\n",
    "                ds[\"keyword\"] = \"re-used\"\n",
    "                ret_val[ds[\"title\"]] = \"re-used\"\n",
    "            else:\n",
    "                ds[\"keyword\"] = \"generated\"\n",
    "                ret_val[ds[\"title\"]] = \"generated\"\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_1_5(self, text):\n",
    "        ret_val = {}\n",
    "        rep = {}\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            \n",
    "            # check if \"input\"\n",
    "            bIsInput = False\n",
    "            for dist in ds[\"distribution\"]:\n",
    "                if dist[\"title\"] == \"Origin\":\n",
    "                    bIsInput = True\n",
    "                    break\n",
    "                    \n",
    "            \n",
    "            if bIsInput:\n",
    "                title = ds[\"title\"].lower()\n",
    "                rep[title]=\";\"+title\n",
    "\n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text.lower()).split(\";\")\n",
    "\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ret_val[ds[\"title\"]] = []\n",
    "            for dist in ds[\"distribution\"]:\n",
    "                if dist[\"title\"] == \"Origin\":\n",
    "                    for line in text:\n",
    "                        if line.startswith(ds[\"title\"].lower()):\n",
    "                            url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', line)\n",
    "                            if len(url) >= 1:\n",
    "                                url = url[0]\n",
    "                                if url.endswith(\".\") or url.endswith(\",\") or url.endswith(\")\"):\n",
    "                                    url = url[:-1]\n",
    "                                ds[\"dataset_id\"] = {\n",
    "                                    \"dataset_id\": url,\n",
    "                                    \"dataset_id_type\": \"HTTP-URI\"\n",
    "                                }\n",
    "                                dist[\"access_url\"]=url\n",
    "                                ret_val[ds[\"title\"]].append({\n",
    "                                    \"dataset_id\": url,\n",
    "                                    \"dataset_id_type\": \"HTTP-URI\",\n",
    "                                    \"access_url\": url\n",
    "                                })\n",
    "                            else:\n",
    "                                ds[\"dataset_id\"] = {\n",
    "                                    \"dataset_id\": ds[\"title\"],\n",
    "                                    \"dataset_id_type\": \"custom\"\n",
    "                                }\n",
    "                                ret_val[ds[\"title\"]].append({\n",
    "                                    \"dataset_id\": ds[\"title\"],\n",
    "                                    \"dataset_id_type\": \"custom\"\n",
    "                                })\n",
    "                            break\n",
    "                else:\n",
    "                    if \"dataset_id\" not in ds:\n",
    "                        ds[\"dataset_id\"] = {\n",
    "                            \"dataset_id\": ds[\"title\"],\n",
    "                            \"dataset_id_type\": \"custom\"\n",
    "                        }\n",
    "                        ret_val[ds[\"title\"]].append({\n",
    "                            \"dataset_id\": ds[\"title\"],\n",
    "                            \"dataset_id_type\": \"custom\"\n",
    "                        })\n",
    "        return ret_val\n",
    " \n",
    "    def parse_question_1_6(self, text):\n",
    "        ret_val = {}\n",
    "        order = ['b', 'kb', 'mb', 'gb', 'tb', 'pb']\n",
    "       \n",
    "        text = self.__split_text_based_on_title(text)\n",
    "\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            for line in text:\n",
    "                if line.startswith(ds[\"title\"].lower()):\n",
    "                    regex1  = re.compile(r'(\\d+(?:\\.\\d+)?)\\s*([kmgtp]?b)', re.IGNORECASE)\n",
    "                    regex2 = re.compile(r'(\\d+(?:\\.\\d+)?)',  re.IGNORECASE)\n",
    "                    size1 = regex1.findall(line)\n",
    "                    size2 = regex2.findall(line)\n",
    "                    if len(size1) >= 1:\n",
    "                        size1 = size1[0]\n",
    "                        size1 = int(float(size1[0]) * (1024**order.index(size1[1].lower())))\n",
    "                        \n",
    "                        for dist in ds[\"distribution\"]:\n",
    "                            dist[\"byte_size\"]=size1\n",
    "                        ret_val[ds[\"title\"]] = size1\n",
    "                    elif len(size2) >= 1:\n",
    "                        size2 = size2[0]                        \n",
    "                        for dist in ds[\"distribution\"]:\n",
    "                            dist[\"byte_size\"]=size2\n",
    "                        ret_val[ds[\"title\"]] = size2\n",
    "        return ret_val\n",
    "\n",
    "    def parse_question_1_7(self, text):\n",
    "        if \"description\" in self.dmp[\"dmp\"]:\n",
    "            text=\";Outline the data utility: to whom will it be useful::\"+text\n",
    "            self.dmp[\"dmp\"][\"description\"] += text\n",
    "        else:\n",
    "            text=\"Outline the data utility: to whom will it be useful::\"+text\n",
    "            self.dmp[\"dmp\"][\"description\"] = text\n",
    "        return text\n",
    "    \n",
    "    def parse_question_2_1_1(self, text):\n",
    "        ret_val = []       \n",
    "        text = self.__split_text_based_on_title(text)\n",
    "\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            for line in text:\n",
    "                if line.startswith(ds[\"title\"].lower()):   \n",
    "                    \n",
    "                    url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', line)\n",
    "                    filename = re.findall('[\\w\\d\\-.\\/:]+\\.\\w+', line)\n",
    "                    if len(url) >= 1:\n",
    "                        url = url[0] \n",
    "                        if url.endswith(\".\") or url.endswith(\",\")  or url.endswith(\")\"):\n",
    "                            url = url[:-1]\n",
    "                        ds[\"metadata\"].append({\n",
    "                            \"description\":\"Dataset Metadata\",\n",
    "                            \"language\":\"en\",\n",
    "                            \"metadata_id\": {\n",
    "                                \"metadata_id\": url,\n",
    "                                \"metadata_id_type\": \"HTTP-URI\"\n",
    "                            }\n",
    "                        })\n",
    "                        ret_val.append({\n",
    "                            \"dataset\": ds[\"title\"],\n",
    "                            \"description\":\"Dataset Metadata\",\n",
    "                            \"language\":\"en\",\n",
    "                            \"metadata_id\": {\n",
    "                                \"metadata_id\": url,\n",
    "                                \"metadata_id_type\": \"HTTP-URI\"\n",
    "                            }\n",
    "                        })\n",
    "                    if len(filename) >= 1:\n",
    "                        new_names = []\n",
    "                        for f in filename:\n",
    "                            if not f.startswith(\"http\"):\n",
    "                                new_names.append(f)\n",
    "                        filename = new_names[0] \n",
    "                        ds[\"metadata\"].append({\n",
    "                            \"description\":\"Dataset Metadata\",\n",
    "                            \"language\":\"en\",\n",
    "                            \"metadata_id\": {\n",
    "                                \"metadata_id\": filename,\n",
    "                                \"metadata_id_type\": \"custom\"\n",
    "                            }\n",
    "                        })\n",
    "                        ret_val.append({\n",
    "                            \"dataset\": ds[\"title\"],\n",
    "                            \"description\":\"Dataset Metadata\",\n",
    "                            \"language\":\"en\",\n",
    "                            \"metadata_id\": {\n",
    "                                \"metadata_id\": filename,\n",
    "                                \"metadata_id_type\": \"custom\"\n",
    "                            }\n",
    "                        })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_1_3(self, text):\n",
    "        ret_val = []\n",
    "        urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "        filenames = re.findall('[\\w\\d\\-.\\/:]+\\.\\w+', text)\n",
    "        \n",
    "        for url in urls:\n",
    "            if url.endswith(\".\") or url.endswith(\",\") or url.endswith(\")\"):\n",
    "                url = url[:-1]\n",
    "            for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                ds[\"metadata\"].append({\n",
    "                    \"description\":\"Naming Conventions\",\n",
    "                    \"language\":\"en\",\n",
    "                    \"metadata_id\": {\n",
    "                        \"metadata_id\": url,\n",
    "                        \"metadata_id_type\": \"HTTP-URI\"\n",
    "                    }\n",
    "                })\n",
    "                ret_val.append({\n",
    "                    \"dataset\": ds[\"title\"],\n",
    "                    \"description\":\"Naming Conventions\",\n",
    "                    \"language\":\"en\",\n",
    "                    \"metadata_id\": {\n",
    "                        \"metadata_id\": url,\n",
    "                        \"metadata_id_type\": \"HTTP-URI\"\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "        for filename in filenames:\n",
    "            if not filename.startswith(\"http\"):\n",
    "                for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                    ds[\"metadata\"].append({\n",
    "                        \"description\":\"Naming Conventions\",\n",
    "                        \"language\":\"en\",\n",
    "                        \"metadata_id\": {\n",
    "                            \"metadata_id\": filename,\n",
    "                            \"metadata_id_type\": \"custom\"\n",
    "                        }\n",
    "                    })\n",
    "                    ret_val.append({\n",
    "                        \"dataset\": ds[\"title\"],\n",
    "                        \"description\":\"Naming Conventions\",\n",
    "                        \"language\":\"en\",\n",
    "                        \"metadata_id\": {\n",
    "                            \"metadata_id\": filename,\n",
    "                            \"metadata_id_type\": \"custom\"\n",
    "                        }\n",
    "                    })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_1_4(self, text):\n",
    "        if \"description\" in self.dmp[\"dmp\"]:\n",
    "            text=\";Outline the approach towards search keyword::\"+text\n",
    "            self.dmp[\"dmp\"][\"description\"] += text\n",
    "        else:\n",
    "            text=\"Outline the approach towards search keyword ::\"+text\n",
    "            self.dmp[\"dmp\"][\"description\"] = text\n",
    "        return text\n",
    "    \n",
    "    def parse_question_2_1_5(self, text):\n",
    "        ret_val = []        \n",
    "        keywords = [\"Endevor\", \"AccuRev SCM\", \"ClearCase\", \"Dimensions CM\", \"IC Manage\", \"PTC Integrity\", \"PVCS\", \"Rational Team Concert\", \"SCM Anywhere\", \"StarTeam\", \"Subversion\", \"SVN\", \"Surround SCM\", \"Vault\", \"Perforce Helix Core\", \"Synergy\", \"Plastic SCM\", \"Azure DevOps\", \"BitKeeper\", \"Code Co-op\", \"darcs\", \"Fossil\", \"Git\", \"Mercurial\", \"Monotone\", \"Pijul\", \"GNU Bazaar\", \"Revision Control System\", \"Source Code Control System\", \"Team Foundation Server\"]\n",
    "        text = text.lower()\n",
    "        for keyword in keywords:\n",
    "            keyword = keyword.lower()\n",
    "            if keyword in text:\n",
    "                for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                    for dist in ds[\"distribution\"]:\n",
    "                        if dist[\"title\"] == \"Project\":\n",
    "                            dist[\"host\"] = {\n",
    "                                \"title\": keyword,\n",
    "                                \"supports_versioning\": \"yes\"\n",
    "                            }\n",
    "                            ret_val.append({\n",
    "                                \"dataset\":ds[\"title\"],\n",
    "                                \"supports_versioning\": \"yes\",\n",
    "                                \"title\": keyword\n",
    "                            })\n",
    "        return ret_val\n",
    "\n",
    "    def parse_question_2_1_6(self, text):\n",
    "        ret_val = []\n",
    "        urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "        filenames = re.findall('[\\w\\d\\-.\\/:]+\\.\\w+', text)\n",
    "        \n",
    "        for url in urls:\n",
    "            if url.endswith(\".\") or url.endswith(\",\") or url.endswith(\")\"):\n",
    "                url = url[:-1]\n",
    "            for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                ds[\"metadata\"].append({\n",
    "                    \"description\":\"Metadata Creation\",\n",
    "                    \"language\":\"en\",\n",
    "                    \"metadata_id\": {\n",
    "                        \"metadata_id\": url,\n",
    "                        \"metadata_id_type\": \"HTTP-URI\"\n",
    "                    }\n",
    "                })\n",
    "                ret_val.append({\n",
    "                    \"dataset\": ds[\"title\"],\n",
    "                    \"description\":\"Metadata Creation\",\n",
    "                    \"language\":\"en\",\n",
    "                    \"metadata_id\": {\n",
    "                        \"metadata_id\": url,\n",
    "                        \"metadata_id_type\": \"HTTP-URI\"\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "        for filename in filenames:\n",
    "            if not filename.startswith(\"http\"):\n",
    "                for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                    ds[\"metadata\"].append({\n",
    "                        \"description\":\"Metadata Creation\",\n",
    "                        \"language\":\"en\",\n",
    "                        \"metadata_id\": {\n",
    "                            \"metadata_id\": filename,\n",
    "                            \"metadata_id_type\": \"custom\"\n",
    "                        }\n",
    "                    })\n",
    "                    ret_val.append({\n",
    "                        \"dataset\": ds[\"title\"],\n",
    "                        \"description\":\"Metadata Creation\",\n",
    "                        \"language\":\"en\",\n",
    "                        \"metadata_id\": {\n",
    "                            \"metadata_id\": filename,\n",
    "                            \"metadata_id_type\": \"custom\"\n",
    "                        }\n",
    "                    })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_2_1(self, text):\n",
    "        ret_val = {}     \n",
    "        text = self.__split_text_based_on_title(text)\n",
    "\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            for line in text:\n",
    "                if line.startswith(ds[\"title\"].lower()):   \n",
    "                    \n",
    "                    state = \"closed\"\n",
    "                    if \"open\" in line.lower():\n",
    "                        state = \"open\"\n",
    "                    if \"closed\" in line.lower():\n",
    "                        state = \"closed\"\n",
    "                    \n",
    "                    for dist in ds[\"distribution\"]:\n",
    "                        dist[\"data_access\"] = state\n",
    "                        ret_val[ds[\"title\"]] = state\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_2_2(self, text):\n",
    "        ret_val = []\n",
    "        urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "        if len(urls) >= 1:\n",
    "            url = urls[0]\n",
    "            if url.endswith(\".\") or url.endswith(\",\") or url.endswith(\")\"):\n",
    "                url = url[:-1]\n",
    "            for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                for dist in ds[\"distribution\"]:\n",
    "                    if dist[\"title\"] == \"Project\":\n",
    "                        dist[\"access_url\"] = url\n",
    "                        tld = re.findall('[^.]*\\.[^.]{2,3}(?:\\.[^.]{2,3})?$', url)\n",
    "                        tld = urlparse(url).netloc\n",
    "                        dist[\"host\"][\"title\"] = tld\n",
    "                        ret_val.append({\"access_url\": url, \"host\":{\"title\":tld}})\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_2_3(self, text):\n",
    "        ret_val = []\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"technical_resource\"].append({\n",
    "                \"description\": text,\n",
    "                \"technical_resource_id\":{\n",
    "                    \"technical_resource_id\": \"software_tools\",\n",
    "                    \"technical_resource_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            ret_val.append({\n",
    "                \"dataset\": ds[\"title\"],\n",
    "                \"description\": text,\n",
    "                \"technical_resource_id\":{\n",
    "                    \"technical_resource_id\": \"software_tools\",\n",
    "                    \"technical_resource_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_2_4(self, text):\n",
    "        return self.parse_question_2_2_2(text)\n",
    "    \n",
    "    def parse_question_2_2_5(self, text):\n",
    "        ret_val = []\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"metadata\"].append({\n",
    "                \"description\": text,\n",
    "                \"metadata_id\":{\n",
    "                    \"metadata_id\": \"restrictions\",\n",
    "                    \"metadata_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            ret_val.append({\n",
    "                \"dataset\": ds[\"title\"],\n",
    "                \"description\": text,\n",
    "                \"metadata_id\":{\n",
    "                    \"metadata_id\": \"restrictions\",\n",
    "                    \"metadata_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_3_1(self, text):\n",
    "        ret_val = []\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"technical_resource\"].append({\n",
    "                \"description\": text,\n",
    "                \"technical_resource_id\":{\n",
    "                    \"technical_resource_id\": \"interoperability_standards\",\n",
    "                    \"technical_resource_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            ret_val.append({\n",
    "                \"dataset\": ds[\"title\"],\n",
    "                \"description\": text,\n",
    "                \"technical_resource_id\":{\n",
    "                    \"technical_resource_id\": \"interoperability_standards\",\n",
    "                    \"technical_resource_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_3_2(self, text):\n",
    "        ret_val = []\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"technical_resource\"].append({\n",
    "                \"description\": text,\n",
    "                \"technical_resource_id\":{\n",
    "                    \"technical_resource_id\": \"vocabulary_standards\",\n",
    "                    \"technical_resource_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            ret_val.append({\n",
    "                \"dataset\": ds[\"title\"],\n",
    "                \"description\": text,\n",
    "                \"technical_resource_id\":{\n",
    "                    \"technical_resource_id\": \"vocabulary_standards\",\n",
    "                    \"technical_resource_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_4_1(self, text):\n",
    "        ret_val = []\n",
    "        urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "        if len(urls) >= 1:\n",
    "            url = urls[0]\n",
    "            if url.endswith(\".\") or url.endswith(\",\") or url.endswith(\")\"):\n",
    "                url = url[:-1]\n",
    "            for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                for dist in ds[\"distribution\"]:\n",
    "                    if dist[\"title\"] == \"Project\":\n",
    "                        dist[\"host\"][\"license\"] = {\n",
    "                            \"license_ref\": url\n",
    "                        }\n",
    "                        ret_val.append({\n",
    "                            \"dataset\": ds[\"title\"],\n",
    "                            \"license_ref\": url\n",
    "                        })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_4_2(self, text):\n",
    "        ret_val = []        \n",
    "        dates = list(datefinder.find_dates(text))\n",
    "        if len(dates) >= 1:\n",
    "            date = dates[0]\n",
    "            for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                for dist in ds[\"distribution\"]:\n",
    "                    if dist[\"title\"] == \"Project\":\n",
    "                        if \"license\" in dist[\"host\"]:\n",
    "                            dist[\"host\"][\"license\"][\"start_date\"] = date.strftime(\"%Y-%d-%m\")\n",
    "                        else:                          \n",
    "                            dist[\"host\"][\"license\"] = {\n",
    "                                \"start_date\": date.strftime(\"%d-%m-%Y\")\n",
    "                            }\n",
    "                        ret_val.append({\n",
    "                            \"dataset\": ds[\"title\"],\n",
    "                            \"start_date\": date.strftime(\"%d-%m-%Y\")\n",
    "                        })\n",
    "        else:\n",
    "            for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                for dist in ds[\"distribution\"]:\n",
    "                    if dist[\"title\"] == \"Project\":\n",
    "                        if \"license\" in dist[\"host\"]:\n",
    "                            dist[\"host\"][\"license\"][\"start_date\"] = self.dmp[\"dmp\"][\"created\"]\n",
    "                        else:                          \n",
    "                            dist[\"host\"][\"license\"] = {\n",
    "                                \"start_date\": self.dmp[\"dmp\"][\"created\"]\n",
    "                            }\n",
    "                        ret_val.append({\n",
    "                            \"dataset\": ds[\"title\"],\n",
    "                            \"start_date\": self.dmp[\"dmp\"][\"created\"]\n",
    "                        })  \n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_4_3(self, text):\n",
    "        ret_val = []\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"metadata\"].append({\n",
    "                \"description\": text,\n",
    "                \"metadata_id\":{\n",
    "                    \"metadata_id\": \"third_party_usability\",\n",
    "                    \"metadata_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            ret_val.append({\n",
    "                \"dataset\": ds[\"title\"],\n",
    "                \"description\": text,\n",
    "                \"metadata_id\":{\n",
    "                    \"metadata_id\": \"third_party_usability\",\n",
    "                    \"metadata_id_type\": \"custom\"\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        return ret_val \n",
    "    \n",
    "    def parse_question_2_4_4(self, text):\n",
    "        ret_val = {}\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"data_quality_assurance\"] = text\n",
    "            ret_val[ds[\"title\"]] = text\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_4_5(self, text):\n",
    "        ret_val = []        \n",
    "        dates = list(datefinder.find_dates(text))\n",
    "        if len(dates) >= 1:\n",
    "            date = dates[0]\n",
    "            for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                for dist in ds[\"distribution\"]:\n",
    "                    if dist[\"title\"] == \"Project\":\n",
    "                        if \"license\" in dist[\"host\"]:\n",
    "                            dist[\"available_till\"] = date.strftime(\"%Y-%d-%m\")\n",
    "                        ret_val.append({\n",
    "                            \"dataset\": ds[\"title\"],\n",
    "                            \"available_till\": date.strftime(\"%d-%m-%Y\")\n",
    "                        })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_3_1(self, text):\n",
    "        cost = {\n",
    "            \"title\": \"Costs for making your data FAIR\",\n",
    "            \"description\": text\n",
    "        }\n",
    "        prices = re.findall('(\\$|€|EUR|USD)(\\d*[.|,]*\\d*)', text)        \n",
    "        if len(prices) >= 1:\n",
    "            price = prices[0]\n",
    "            code = price[0]\n",
    "            if code.lower().startswith(\"eur\"):\n",
    "                cost[\"currency_code\"] = \"EUR\"\n",
    "                cost[\"value\"] = price[1]\n",
    "            if code.lower().startswith(\"usd\"):\n",
    "                cost[\"currency_code\"] = \"USD\"\n",
    "                cost[\"value\"] = price[1]\n",
    "            if code.lower().startswith(\"$\"):\n",
    "                cost[\"currency_code\"] = \"USD\"\n",
    "                cost[\"value\"] = price[1]\n",
    "            if code.lower().startswith(\"€\"):\n",
    "                cost[\"currency_code\"] = \"EUR\"\n",
    "                cost[\"value\"] = price[1]\n",
    "            \n",
    "        self.dmp[\"dmp\"][\"cost\"] = [cost]\n",
    "        return cost\n",
    "    \n",
    "    def parse_question_3_2(self, text):\n",
    "        dmp_staff = []\n",
    "        \n",
    "        lines = text.split(\"\\n\")        \n",
    "        current_staff = None\n",
    "        for line in lines:\n",
    "            # is URL?\n",
    "            url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', line)\n",
    "            if len(url) >= 1:\n",
    "                current_staff[\"staff_id\"] = {\n",
    "                    \"staff_id\":url[0],\n",
    "                    \"staff_id_type\": \"HTTP-ORCID\"\n",
    "                }\n",
    "                continue\n",
    "                \n",
    "            # is EMAIL?\n",
    "            email = re.findall(r'[\\w\\.]+\\@[\\w]+(?:\\.[\\w]{3}|\\.[\\w]{2}\\.[\\w]{2})\\b', line)\n",
    "            if len(email) >= 1:\n",
    "                current_staff[\"mbox\"] = email[0]\n",
    "                continue\n",
    "                \n",
    "            # else new staff\n",
    "            if current_staff != None:\n",
    "                dmp_staff.append(current_staff)\n",
    "            current_staff = {}    \n",
    "            current_staff[\"name\"] = line\n",
    "            \n",
    "        if current_staff != None:\n",
    "            dmp_staff.append(current_staff)\n",
    "        \n",
    "        self.dmp[\"dmp\"][\"dm_staff\"] = dmp_staff\n",
    "        return dmp_staff\n",
    "    \n",
    "    def parse_question_3_3(self, text):\n",
    "        ret_val = {}\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"preservation_statement\"] = text\n",
    "            ret_val[ds[\"title\"]] = text\n",
    "        return ret_val\n",
    "\n",
    "    def parse_question_4_1(self, text):\n",
    "        ret_val = []\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"security_and_privacy\"] = [{\n",
    "                \"title\": \"Data Security\",\n",
    "                \"text\": text\n",
    "            }]\n",
    "            ret_val.append({\n",
    "                \"dataset\": ds[\"title\"],\n",
    "                \"title\": \"Data Security\",\n",
    "                \"text\": text\n",
    "            })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_5_1(self, text):\n",
    "        ret_val = {}\n",
    "        \n",
    "        self.dmp[\"dmp\"][\"ethical_issues_description\"] = text\n",
    "        ret_val[\"ethical_issues_description\"] = text\n",
    "        \n",
    "        self.dmp[\"dmp\"][\"ethical_issues_exist\"] = \"no\"\n",
    "        ret_val[\"ethical_issues_exist\"] = \"no\"\n",
    "        \n",
    "        url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "        if len(url)>=1:\n",
    "            url = url[0]\n",
    "            if url.endswith(\".\") or url.endswith(\",\") or url.endswith(\")\"):\n",
    "                url = url[:-1]\n",
    "            self.dmp[\"dmp\"][\"ethical_issues_report\"] = url\n",
    "            ret_val[\"ethical_issues_report\"] = url\n",
    "            \n",
    "            self.dmp[\"dmp\"][\"ethical_issues_exist\"] = \"yes\"\n",
    "            ret_val[\"ethical_issues_exist\"] = \"yes\"\n",
    "            \n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_6_1(self, text):\n",
    "        q = \"Refer to other national/funder/sectorial/departmental procedures for data management that you are using (if any)\"\n",
    "        if \"description\" in self.dmp[\"dmp\"][\"project\"]:\n",
    "            text=\";\"+q+\"::\"+text\n",
    "            self.dmp[\"dmp\"][\"project\"][\"description\"] += text\n",
    "        else:\n",
    "            text=q+\"::\"+text\n",
    "            self.dmp[\"dmp\"][\"project\"][\"description\"] = text\n",
    "        return text\n",
    "    \n",
    "    def generate(self):\n",
    "        return json.dumps(self.dmp, indent=2, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test HorizonParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmp_title = \"Parser Test\"\n",
    "dmp_description = \"DMP Abstract is located here\"\n",
    "dmp_created = \"2017-01-01\" \n",
    "dmp_modified = \"2018-01-01\"\n",
    "dmp_id = \"http://validorcid.com/12345\"\n",
    "pi_name = \"Martin Pichler\"\n",
    "pi_mail = \"pichler.martin@outlook.at\"\n",
    "pi_orcid = \"https://orcid.org/0000-0001-5305-9063\"\n",
    "\n",
    "horizon_parser = HorizonParser(dmp_title, dmp_description, dmp_created, dmp_modified, dmp_id, pi_name, pi_mail, pi_orcid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'State the purpose of the data collection/generation::No new data was collected for this project. Only data from the Austrian and European open data portals has been used. The generated data are images that are used to draw conclusions between the divorce rate of Austria and the EU28.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_1_test_1 = \"No new data was collected for this project. Only data from the Austrian and European open data portals has been used. The generated data are images that are used to draw conclusions between the divorce rate of Austria and the EU28.\"\n",
    "\n",
    "horizon_parser.parse_question_1_1(q1_1_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "';Explain the relation to the objectives of the project::The input data contains the annual number of divorces for Austria and the EU. The produced data is a visual analysis of the correlation between the Austrian and the EU28 divorce rate.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_2_test_1 = \"The input data contains the annual number of divorces for Austria and the EU. The produced data is a visual analysis of the correlation between the Austrian and the EU28 divorce rate.\"\n",
    "\n",
    "horizon_parser.parse_question_1_2(q1_2_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'Divorce statistic of austria',\n",
       "  'type': 'Dataset',\n",
       "  'distribution': [{'title': 'Origin', 'format': 'csv'},\n",
       "   {'title': 'Project', 'format': 'csv'}],\n",
       "  'metadata': [],\n",
       "  'technical_resource': []},\n",
       " {'title': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'Divorce statistic of the EU',\n",
       "  'type': 'Dataset',\n",
       "  'distribution': [{'title': 'Origin', 'format': 'tsv'},\n",
       "   {'title': 'Project', 'format': 'tsv'}],\n",
       "  'metadata': [],\n",
       "  'technical_resource': []},\n",
       " {'title': 'scatter',\n",
       "  'description': 'Scatterplot',\n",
       "  'type': 'Image',\n",
       "  'distribution': [{'title': 'Project', 'format': 'png'}],\n",
       "  'metadata': [],\n",
       "  'technical_resource': []},\n",
       " {'title': 'time_change',\n",
       "  'description': 'Time Change Plot',\n",
       "  'type': 'Image',\n",
       "  'distribution': [{'title': 'Project', 'format': 'png'}],\n",
       "  'metadata': [],\n",
       "  'technical_resource': []},\n",
       " {'title': 'time_corr',\n",
       "  'description': 'Time Correlation Plot',\n",
       "  'type': 'Image',\n",
       "  'distribution': [{'title': 'Project', 'format': 'png'}],\n",
       "  'metadata': [],\n",
       "  'technical_resource': []}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q1_3_test_1 = \"\"\"Title: Ehescheidungen (Statistik Austria)\n",
    "Description: Divorce statistic of austria\n",
    "Type: Dataset\n",
    "Format: csv\n",
    "Source: Input\n",
    "\n",
    "title: Divorces by duration of marriage (Eurostat)description: Divorce statistic of the EUType: DatasetFormat: tsvSource: Input\n",
    "\n",
    "Title: scatter\n",
    "Description: Scatterplot\n",
    "Type: Image\n",
    "Format: png\n",
    "Source: Produced\n",
    "\n",
    "Title:time_change\n",
    "Description:Time Change Plot\n",
    "Type:Image\n",
    "Format:png\n",
    "Source:Produced\n",
    "\n",
    "Title: time_corr\n",
    "Description: Time Correlation Plot\n",
    "Type: Image\n",
    "Format: png\n",
    "Source: Produced\"\"\"\n",
    "\n",
    "q1_3_test_2 = \"\"\"Title: Ehescheidungen (Statistik Austria)\n",
    "Description: Divorce statistic of austria\n",
    "Type: Dataset\n",
    "Format: csv\n",
    "Source: Input\n",
    "\n",
    "title: Divorces by duration of marriage (Eurostat)description: Divorce statistic of the EUType: DatasetFormat: tsvSource: Input\n",
    "\n",
    "Title: scatter\n",
    "Description: Scatterplot\n",
    "Type: Image\n",
    "Format: png\n",
    "Source: Produced\n",
    "\n",
    "Title:time_change\n",
    "Description:Time Change Plot\n",
    "Type:Image\n",
    "Format:png\n",
    "Source:Produced\n",
    "\n",
    "Title: time_corr\n",
    "Description: Time Correlation Plot\n",
    "Type: Image\n",
    "\"\"\"\n",
    "\n",
    "display(horizon_parser.parse_question_1_3(q1_3_test_1))\n",
    "#display(horizon_parser.parse_question_1_3(q1_3_test_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ehescheidungen (Statistik Austria)': 're-used',\n",
       " 'Divorces by duration of marriage (Eurostat)': 're-used',\n",
       " 'scatter': 'generated',\n",
       " 'time_change': 'generated',\n",
       " 'time_corr': 'generated'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_4_test_1 = \"Ehescheidungen (Statistik Austria) and Divorces by duration of marriage (Eurostat) are re-used for this project.\"\n",
    "\n",
    "horizon_parser.parse_question_1_4(q1_4_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ehescheidungen (Statistik Austria)': [{'dataset_id': 'https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c',\n",
       "   'dataset_id_type': 'HTTP-URI',\n",
       "   'access_url': 'https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c'}],\n",
       " 'Divorces by duration of marriage (Eurostat)': [{'dataset_id': 'https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur',\n",
       "   'dataset_id_type': 'HTTP-URI',\n",
       "   'access_url': 'https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur'}],\n",
       " 'scatter': [{'dataset_id': 'scatter', 'dataset_id_type': 'custom'}],\n",
       " 'time_change': [{'dataset_id': 'time_change', 'dataset_id_type': 'custom'}],\n",
       " 'time_corr': [{'dataset_id': 'time_corr', 'dataset_id_type': 'custom'}]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_5_test_1 = \"\"\"Ehescheidungen (Statistik Austria) was downloaded from https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c.\n",
    "\n",
    "Divorces by duration of marriage (Eurostat) was downloaded from https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur.\n",
    "\n",
    "scatter was produced during research.\n",
    "\n",
    "time_change was produced during research.\n",
    "\n",
    "time_corr was produced during research.\"\"\"\n",
    "\n",
    "\n",
    "q1_5_test_2 = \"\"\"Ehescheidungen (Statistik Austria) was downloaded from https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c.\n",
    "\n",
    "scatter was produced during research.\n",
    "\n",
    "time_corr was produced during research.\"\"\"\n",
    "\n",
    "q1_5test_3 = \"\"\"\n",
    "Ehescheidungen (Statistik Austria) was downloaded from https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c.\n",
    "Divorces by duration of marriage (Eurostat) was downloaded from https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur.\n",
    "scatter was produced during research.\n",
    "time_change was produced during research.\n",
    "time_corr was produced during research.\n",
    "Error while connecting to PostgreSQL ''\n",
    "PostgreSQL connection is closed\n",
    "\"\"\"\n",
    "\n",
    "horizon_parser.parse_question_1_5(q1_5_test_1)\n",
    "#horizon_parser.parse_question_1_5(q1_5_test_2)\n",
    "#orizon_parser.parse_question_1_5(q1_5test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ehescheidungen (Statistik Austria)': 1024,\n",
       " 'Divorces by duration of marriage (Eurostat)': 304128,\n",
       " 'scatter': '15360',\n",
       " 'time_change': 30720,\n",
       " 'time_corr': 15360}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_6_test_1 = \"\"\"Ehescheidungen (Statistik Austria) has a size of 1KB\n",
    "\n",
    "Divorces by duration of marriage (Eurostat) has a size of 297KB\n",
    "\n",
    "scatter has a size of 15360\n",
    "\n",
    "time_change has a size of 30KB\n",
    "\n",
    "time_corr has a size of 15KB\"\"\"\n",
    "\n",
    "horizon_parser.parse_question_1_6(q1_6_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "';Outline the data utility: to whom will it be useful::Storing the data makes it easy for other people to rerun and validate the correctness of the experiment. It also avoids the possible loss of the original data through the third-party providers and guarantees access to the data.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_7_test_1 = \"Storing the data makes it easy for other people to rerun and validate the correctness of the experiment. It also avoids the possible loss of the original data through the third-party providers and guarantees access to the data.\"\n",
    "\n",
    "horizon_parser.parse_question_1_7(q1_7_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'Dataset Metadata',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c',\n",
       "   'metadata_id_type': 'HTTP-URI'}},\n",
       " {'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'Dataset Metadata',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'divorce_analysis.ipynb',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'Dataset Metadata',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'http://data.europa.eu/euodp/en/data/dataset/brjas74zddipeu7mnkhmia',\n",
       "   'metadata_id_type': 'HTTP-URI'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'Dataset Metadata',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'divorce_analysis.ipynb',\n",
       "   'metadata_id_type': 'custom'}}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_1_1_test_1 = \"The metadata description for Ehescheidungen (Statistik Austria) can be found in the jupyter notebook file divorce_analysis.ipynb or can be accessed online at https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c. The metadata description for Divorces by duration of marriage (Eurostat) is stored in the same file \\\"divorce_analysis.ipynb\\\" or online at http://data.europa.eu/euodp/en/data/dataset/bRJAS74ZDdIpeU7mnKhMiA.\"\n",
    "\n",
    "q2_1_1_test_2 = \"The metadata description for Ehescheidungen (Statistik Austria) can be accessed online at https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c or can be found in the jupyter notebook file divorce_analysis.ipynb. The metadata description for Divorces by duration of marriage (Eurostat) is stored in the same file \\\"divorce_analysis.ipynb\\\" or online at http://data.europa.eu/euodp/en/data/dataset/bRJAS74ZDdIpeU7mnKhMiA.\"\n",
    "\n",
    "\n",
    "horizon_parser.parse_question_2_1_1(q2_1_1_test_1)\n",
    "#horizon_parser.parse_question_2_1_1(q2_1_1_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.1.2\n",
    "\n",
    "No processing needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'Naming Conventions',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html',\n",
       "   'metadata_id_type': 'HTTP-URI'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'Naming Conventions',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html',\n",
       "   'metadata_id_type': 'HTTP-URI'}},\n",
       " {'dataset': 'scatter',\n",
       "  'description': 'Naming Conventions',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html',\n",
       "   'metadata_id_type': 'HTTP-URI'}},\n",
       " {'dataset': 'time_change',\n",
       "  'description': 'Naming Conventions',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html',\n",
       "   'metadata_id_type': 'HTTP-URI'}},\n",
       " {'dataset': 'time_corr',\n",
       "  'description': 'Naming Conventions',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html',\n",
       "   'metadata_id_type': 'HTTP-URI'}}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_1_3_test_1 = \"\"\"The input files are saved with their original file names as provided by their original source. \n",
    "\n",
    "Other files, code and data use naming conventions commonly used with python (https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html)\"\"\"\n",
    "\n",
    "q2_1_3_test_2 = \"\"\"The input files are saved with their original file names as provided by their original source. \n",
    "\n",
    "Other files, code and data use naming conventions commonly used with python (https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html)\n",
    "\n",
    "We also provide them in the file conventions.txt\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "horizon_parser.parse_question_2_1_3(q2_1_3_test_1)\n",
    "#horizon_parser.parse_question_2_1_3(q2_1_3_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "';Outline the approach towards search keyword::Not implemented.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_1_4_test_1 = \"Not implemented.\"\n",
    "\n",
    "horizon_parser.parse_question_2_1_4(q2_1_4_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'supports_versioning': 'yes',\n",
       "  'title': 'git'},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'supports_versioning': 'yes',\n",
       "  'title': 'git'},\n",
       " {'dataset': 'scatter', 'supports_versioning': 'yes', 'title': 'git'},\n",
       " {'dataset': 'time_change', 'supports_versioning': 'yes', 'title': 'git'},\n",
       " {'dataset': 'time_corr', 'supports_versioning': 'yes', 'title': 'git'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_1_5_test_1 = \"\"\"The original release was versioned as v1.0.0. Every further release however will follow a date based versioning pattern <year>.<month>.<day>.<sequence_within_day> (e.g. 2019.04.19.01).\n",
    "\n",
    "Since the project is hosted as a git repository, keeping track of changes to the data is handled automatically.\"\"\"\n",
    "\n",
    "horizon_parser.parse_question_2_1_5(q2_1_5_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_1_6_test_1 = \"The metadata in the jupyter notebook contains information about the original fields of the input data and what part of it actually is used in the project.\"\n",
    "\n",
    "q2_1_6_test_2 = \"The metadata in the jupyter notebook (divorce_analysis.ipynb) contains information about the original fields of the input data and what part of it actually is used in the project.\"\n",
    "\n",
    "\n",
    "horizon_parser.parse_question_2_1_6(q2_1_6_test_1)\n",
    "#horizon_parser.parse_question_2_1_6(q2_1_6_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ehescheidungen (Statistik Austria)': 'open',\n",
       " 'Divorces by duration of marriage (Eurostat)': 'open',\n",
       " 'scatter': 'open',\n",
       " 'time_change': 'open',\n",
       " 'time_corr': 'open'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_2_1_test_1 = \"\"\"Ehescheidungen (Statistik Austria) is open access.\n",
    "\n",
    "Divorces by duration of marriage (Eurostat) is open access.\n",
    "\n",
    "scatter is open access\n",
    "\n",
    "time_change is open access\n",
    "\n",
    "time_corr is open access\"\"\"\n",
    "\n",
    "q2_2_1_test_2 = \"\"\"Ehescheidungen (Statistik Austria) is closed access.\n",
    "\n",
    "Divorces by duration of marriage (Eurostat) is closed access.\n",
    "\n",
    "scatter is open access\n",
    "\n",
    "time_change is open access\n",
    "\n",
    "time_corr is open access\"\"\"\n",
    "\n",
    "q2_2_1_test_3 = \"\"\"Ehescheidungen (Statistik Austria) is closed access.\n",
    "\n",
    "Divorces by duration of marriage (Eurostat) is closed access.\n",
    "\n",
    "scatter is open access\n",
    "\n",
    "time_change is undefined access\n",
    " \n",
    "time_corr is open and closed access\"\"\"\n",
    "\n",
    "horizon_parser.parse_question_2_2_1(q2_2_1_test_1)\n",
    "#horizon_parser.parse_question_2_2_1(q2_2_1_test_2)\n",
    "#horizon_parser.parse_question_2_2_1(q2_2_1_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_2_2_test_1 = \"The data can be accessed through Github (https://github.com/martinpichler/data_stewardship_ex1).\"\n",
    "\n",
    "horizon_parser.parse_question_2_2_2(q2_2_2_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'software_tools',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'software_tools',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'scatter',\n",
       "  'description': 'The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'software_tools',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'time_change',\n",
       "  'description': 'The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'software_tools',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'time_corr',\n",
       "  'description': 'The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'software_tools',\n",
       "   'technical_resource_id_type': 'custom'}}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_2_3_test_1 = \"\"\"The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\n",
    "\n",
    "The input data files are stored as .csv and .tsv files and need no additional software. \n",
    "\n",
    "The produced data are .png images and an image viewer is needed to open them.\"\"\"\n",
    "\n",
    "horizon_parser.parse_question_2_2_3(q2_2_3_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_2_4_test_1 = \"As stated in previous sections, the complete project is available on Github (https://github.com/martinpichler/data_stewardship_ex1).\"\n",
    "\n",
    "horizon_parser.parse_question_2_2_4(q2_2_4_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'No restrictions, access is public and open to everyone.',\n",
       "  'metadata_id': {'metadata_id': 'restrictions',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'No restrictions, access is public and open to everyone.',\n",
       "  'metadata_id': {'metadata_id': 'restrictions',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'scatter',\n",
       "  'description': 'No restrictions, access is public and open to everyone.',\n",
       "  'metadata_id': {'metadata_id': 'restrictions',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'time_change',\n",
       "  'description': 'No restrictions, access is public and open to everyone.',\n",
       "  'metadata_id': {'metadata_id': 'restrictions',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'time_corr',\n",
       "  'description': 'No restrictions, access is public and open to everyone.',\n",
       "  'metadata_id': {'metadata_id': 'restrictions',\n",
       "   'metadata_id_type': 'custom'}}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_2_5_test_1 = \"No restrictions, access is public and open to everyone.\"\n",
    "\n",
    "horizon_parser.parse_question_2_2_5(q2_2_5_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'interoperability_standards',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'interoperability_standards',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'scatter',\n",
       "  'description': 'All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'interoperability_standards',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'time_change',\n",
       "  'description': 'All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'interoperability_standards',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'time_corr',\n",
       "  'description': 'All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'interoperability_standards',\n",
       "   'technical_resource_id_type': 'custom'}}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_3_1_test_1 = \"\"\"All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\n",
    "\n",
    "There is no domain-specific vocabulary to take in consideration.\"\"\"\n",
    "\n",
    "horizon_parser.parse_question_2_3_1(q2_3_1_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'Standard vocabulary is used, no mapping required.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'vocabulary_standards',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'Standard vocabulary is used, no mapping required.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'vocabulary_standards',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'scatter',\n",
       "  'description': 'Standard vocabulary is used, no mapping required.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'vocabulary_standards',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'time_change',\n",
       "  'description': 'Standard vocabulary is used, no mapping required.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'vocabulary_standards',\n",
       "   'technical_resource_id_type': 'custom'}},\n",
       " {'dataset': 'time_corr',\n",
       "  'description': 'Standard vocabulary is used, no mapping required.',\n",
       "  'technical_resource_id': {'technical_resource_id': 'vocabulary_standards',\n",
       "   'technical_resource_id_type': 'custom'}}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_3_2_test_1 = \"Standard vocabulary is used, no mapping required.\"\n",
    "\n",
    "horizon_parser.parse_question_2_3_2(q2_3_2_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'license_ref': 'https://opensource.org/licenses/MIT'},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'license_ref': 'https://opensource.org/licenses/MIT'},\n",
       " {'dataset': 'scatter', 'license_ref': 'https://opensource.org/licenses/MIT'},\n",
       " {'dataset': 'time_change',\n",
       "  'license_ref': 'https://opensource.org/licenses/MIT'},\n",
       " {'dataset': 'time_corr',\n",
       "  'license_ref': 'https://opensource.org/licenses/MIT'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_4_1_test_1 = \"The project is licenced under the MIT licence (https://opensource.org/licenses/MIT) and open for re-use by anyone.\"\n",
    "\n",
    "horizon_parser.parse_question_2_4_1(q2_4_1_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)', 'start_date': '2017-01-01'},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'start_date': '2017-01-01'},\n",
       " {'dataset': 'scatter', 'start_date': '2017-01-01'},\n",
       " {'dataset': 'time_change', 'start_date': '2017-01-01'},\n",
       " {'dataset': 'time_corr', 'start_date': '2017-01-01'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_4_2_test_1 = \"Already openly available.\"\n",
    "q2_4_2_test_2 = \"The data will be made available on 2017-06-06\"\n",
    "\n",
    "\n",
    "horizon_parser.parse_question_2_4_2(q2_4_2_test_1)\n",
    "#horizon_parser.parse_question_2_4_2(q2_4_2_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'No restrictions, data and source code can be used by anyone.',\n",
       "  'metadata_id': {'metadata_id': 'third_party_usability',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'No restrictions, data and source code can be used by anyone.',\n",
       "  'metadata_id': {'metadata_id': 'third_party_usability',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'scatter',\n",
       "  'description': 'No restrictions, data and source code can be used by anyone.',\n",
       "  'metadata_id': {'metadata_id': 'third_party_usability',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'time_change',\n",
       "  'description': 'No restrictions, data and source code can be used by anyone.',\n",
       "  'metadata_id': {'metadata_id': 'third_party_usability',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'time_corr',\n",
       "  'description': 'No restrictions, data and source code can be used by anyone.',\n",
       "  'metadata_id': {'metadata_id': 'third_party_usability',\n",
       "   'metadata_id_type': 'custom'}}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_4_3_test_1 = \"No restrictions, data and source code can be used by anyone.\"\n",
    "\n",
    "horizon_parser.parse_question_2_4_3(q2_4_3_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ehescheidungen (Statistik Austria)': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.',\n",
       " 'Divorces by duration of marriage (Eurostat)': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.',\n",
       " 'scatter': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.',\n",
       " 'time_change': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.',\n",
       " 'time_corr': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_4_4_test_1 = \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\"\n",
    "\n",
    "horizon_parser.parse_question_2_4_4(q2_4_4_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_4_5_test_1 = \"There is no limit on how long the data will remain re-usable.\"\n",
    "q2_4_5_test_2 = \"The data will be usable till 2019-01-01\"\n",
    "\n",
    "\n",
    "horizon_parser.parse_question_2_4_5(q2_4_5_test_1)\n",
    "#horizon_parser.parse_question_2_4_5(q2_4_5_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Costs for making your data FAIR',\n",
       " 'description': 'Since the data is stored in a public Github repository, no additional cost has to be covered.'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_1_test_1 = \"Since the data is stored in a public Github repository, no additional cost has to be covered.\"\n",
    "q3_1_test_2 = \"cost are $100\"\n",
    "q3_1_test_3 = \"costs are EUR100\"\n",
    "\n",
    "horizon_parser.parse_question_3_1(q3_1_test_1)\n",
    "#horizon_parser.parse_question_3_1(q3_1_test_2)\n",
    "#horizon_parser.parse_question_3_1(q3_1_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Martin Pichler',\n",
       "  'mbox': 'mpichler.dev@gmail.com',\n",
       "  'staff_id': {'staff_id': 'https://orcid.org/0000-0001-5305-9063',\n",
       "   'staff_id_type': 'HTTP-ORCID'}}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_2_test_1 = \"\"\"Martin Pichler\n",
    "mpichler.dev@gmail.com\n",
    "https://orcid.org/0000-0001-5305-9063\"\"\"\n",
    "\n",
    "q3_2_test_2 = \"\"\"Martin Pichler\n",
    "mpichler.dev@gmail.com\n",
    "https://orcid.org/0000-0001-5305-9063\n",
    "Other Person\n",
    "other.mail@mail.com\n",
    "https://orcid.org/0000-0001-5305-9063\"\"\"\n",
    "\n",
    "horizon_parser.parse_question_3_2(q3_2_test_1)\n",
    "#horizon_parser.parse_question_3_2(q3_2_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ehescheidungen (Statistik Austria)': 'Since the data is stored in a public Github repository, no additional cost has to be covered.',\n",
       " 'Divorces by duration of marriage (Eurostat)': 'Since the data is stored in a public Github repository, no additional cost has to be covered.',\n",
       " 'scatter': 'Since the data is stored in a public Github repository, no additional cost has to be covered.',\n",
       " 'time_change': 'Since the data is stored in a public Github repository, no additional cost has to be covered.',\n",
       " 'time_corr': 'Since the data is stored in a public Github repository, no additional cost has to be covered.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_3_test_1 = \"Since the data is stored in a public Github repository, no additional cost has to be covered.\"\n",
    "\n",
    "horizon_parser.parse_question_3_3(q3_3_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'},\n",
       " {'dataset': 'scatter',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'},\n",
       " {'dataset': 'time_change',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'},\n",
       " {'dataset': 'time_corr',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q4_1_test_1 = \"Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.\"\n",
    "\n",
    "horizon_parser.parse_question_4_1(q4_1_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ethical_issues_description': 'No ethical issues exist',\n",
       " 'ethical_issues_exist': 'no'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q5_1_test_1 = \"No ethical issues exist\"\n",
    "\n",
    "q5_1_test_2 = \"Ethical issues are reported at http://www.issues.com\"\n",
    "\n",
    "horizon_parser.parse_question_5_1(q5_1_test_1)\n",
    "#horizon_parser.parse_question_5_1(q5_1_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "';Refer to other national/funder/sectorial/departmental procedures for data management that you are using (if any)::No additional procedures are used.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q6_1_test_1 = \"No additional procedures are used.\"\n",
    "\n",
    "horizon_parser.parse_question_6_1(q6_1_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dmp\": {\n",
      "    \"title\": \"Parser Test\",\n",
      "    \"description\": \"Abstract::DMP Abstract is located here;Explain the relation to the objectives of the project::The input data contains the annual number of divorces for Austria and the EU. The produced data is a visual analysis of the correlation between the Austrian and the EU28 divorce rate.;Outline the data utility: to whom will it be useful::Storing the data makes it easy for other people to rerun and validate the correctness of the experiment. It also avoids the possible loss of the original data through the third-party providers and guarantees access to the data.;Outline the approach towards search keyword::Not implemented.\",\n",
      "    \"created\": \"2017-01-01\",\n",
      "    \"modified\": \"2018-01-01\",\n",
      "    \"dmp_id\": {\n",
      "      \"dmp_id\": \"http://validorcid.com/12345\",\n",
      "      \"dmp_id_type\": \"HTTP-DOI\"\n",
      "    },\n",
      "    \"contact\": {\n",
      "      \"name\": \"Martin Pichler\",\n",
      "      \"mail\": \"pichler.martin@outlook.at\",\n",
      "      \"contact_id\": {\n",
      "        \"contact_id\": \"https://orcid.org/0000-0001-5305-9063\",\n",
      "        \"contact_id_type\": \"HTTP-ORCID\"\n",
      "      }\n",
      "    },\n",
      "    \"project\": {\n",
      "      \"description\": \"State the purpose of the data collection/generation::No new data was collected for this project. Only data from the Austrian and European open data portals has been used. The generated data are images that are used to draw conclusions between the divorce rate of Austria and the EU28.;Refer to other national/funder/sectorial/departmental procedures for data management that you are using (if any)::No additional procedures are used.\"\n",
      "    },\n",
      "    \"dataset\": [\n",
      "      {\n",
      "        \"title\": \"Ehescheidungen (Statistik Austria)\",\n",
      "        \"description\": \"Divorce statistic of austria\",\n",
      "        \"type\": \"Dataset\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Origin\",\n",
      "            \"format\": \"csv\",\n",
      "            \"access_url\": \"https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c\",\n",
      "            \"byte_size\": 1024,\n",
      "            \"data_access\": \"open\"\n",
      "          },\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"csv\",\n",
      "            \"byte_size\": 1024,\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\",\n",
      "              \"license\": {\n",
      "                \"license_ref\": \"https://opensource.org/licenses/MIT\",\n",
      "                \"start_date\": \"2017-01-01\"\n",
      "              }\n",
      "            },\n",
      "            \"data_access\": \"open\",\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [\n",
      "          {\n",
      "            \"description\": \"Dataset Metadata\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c\",\n",
      "              \"metadata_id_type\": \"HTTP-URI\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Dataset Metadata\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"divorce_analysis.ipynb\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Naming Conventions\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html\",\n",
      "              \"metadata_id_type\": \"HTTP-URI\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, access is public and open to everyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"restrictions\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, data and source code can be used by anyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"third_party_usability\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"technical_resource\": [\n",
      "          {\n",
      "            \"description\": \"The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"software_tools\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"interoperability_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Standard vocabulary is used, no mapping required.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"vocabulary_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"keyword\": \"re-used\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c\",\n",
      "          \"dataset_id_type\": \"HTTP-URI\"\n",
      "        },\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"preservation_statement\": \"Since the data is stored in a public Github repository, no additional cost has to be covered.\",\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"Divorces by duration of marriage (Eurostat)\",\n",
      "        \"description\": \"Divorce statistic of the EU\",\n",
      "        \"type\": \"Dataset\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Origin\",\n",
      "            \"format\": \"tsv\",\n",
      "            \"access_url\": \"https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur\",\n",
      "            \"byte_size\": 304128,\n",
      "            \"data_access\": \"open\"\n",
      "          },\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"tsv\",\n",
      "            \"byte_size\": 304128,\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\",\n",
      "              \"license\": {\n",
      "                \"license_ref\": \"https://opensource.org/licenses/MIT\",\n",
      "                \"start_date\": \"2017-01-01\"\n",
      "              }\n",
      "            },\n",
      "            \"data_access\": \"open\",\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [\n",
      "          {\n",
      "            \"description\": \"Dataset Metadata\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"http://data.europa.eu/euodp/en/data/dataset/brjas74zddipeu7mnkhmia\",\n",
      "              \"metadata_id_type\": \"HTTP-URI\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Dataset Metadata\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"divorce_analysis.ipynb\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Naming Conventions\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html\",\n",
      "              \"metadata_id_type\": \"HTTP-URI\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, access is public and open to everyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"restrictions\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, data and source code can be used by anyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"third_party_usability\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"technical_resource\": [\n",
      "          {\n",
      "            \"description\": \"The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"software_tools\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"interoperability_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Standard vocabulary is used, no mapping required.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"vocabulary_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"keyword\": \"re-used\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur\",\n",
      "          \"dataset_id_type\": \"HTTP-URI\"\n",
      "        },\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"preservation_statement\": \"Since the data is stored in a public Github repository, no additional cost has to be covered.\",\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"scatter\",\n",
      "        \"description\": \"Scatterplot\",\n",
      "        \"type\": \"Image\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"png\",\n",
      "            \"byte_size\": \"15360\",\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\",\n",
      "              \"license\": {\n",
      "                \"license_ref\": \"https://opensource.org/licenses/MIT\",\n",
      "                \"start_date\": \"2017-01-01\"\n",
      "              }\n",
      "            },\n",
      "            \"data_access\": \"open\",\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [\n",
      "          {\n",
      "            \"description\": \"Naming Conventions\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html\",\n",
      "              \"metadata_id_type\": \"HTTP-URI\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, access is public and open to everyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"restrictions\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, data and source code can be used by anyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"third_party_usability\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"technical_resource\": [\n",
      "          {\n",
      "            \"description\": \"The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"software_tools\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"interoperability_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Standard vocabulary is used, no mapping required.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"vocabulary_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"keyword\": \"generated\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"scatter\",\n",
      "          \"dataset_id_type\": \"custom\"\n",
      "        },\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"preservation_statement\": \"Since the data is stored in a public Github repository, no additional cost has to be covered.\",\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"time_change\",\n",
      "        \"description\": \"Time Change Plot\",\n",
      "        \"type\": \"Image\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"png\",\n",
      "            \"byte_size\": 30720,\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\",\n",
      "              \"license\": {\n",
      "                \"license_ref\": \"https://opensource.org/licenses/MIT\",\n",
      "                \"start_date\": \"2017-01-01\"\n",
      "              }\n",
      "            },\n",
      "            \"data_access\": \"open\",\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [\n",
      "          {\n",
      "            \"description\": \"Naming Conventions\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html\",\n",
      "              \"metadata_id_type\": \"HTTP-URI\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, access is public and open to everyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"restrictions\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, data and source code can be used by anyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"third_party_usability\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"technical_resource\": [\n",
      "          {\n",
      "            \"description\": \"The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"software_tools\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"interoperability_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Standard vocabulary is used, no mapping required.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"vocabulary_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"keyword\": \"generated\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"time_change\",\n",
      "          \"dataset_id_type\": \"custom\"\n",
      "        },\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"preservation_statement\": \"Since the data is stored in a public Github repository, no additional cost has to be covered.\",\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"time_corr\",\n",
      "        \"description\": \"Time Correlation Plot\",\n",
      "        \"type\": \"Image\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"png\",\n",
      "            \"byte_size\": 15360,\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\",\n",
      "              \"license\": {\n",
      "                \"license_ref\": \"https://opensource.org/licenses/MIT\",\n",
      "                \"start_date\": \"2017-01-01\"\n",
      "              }\n",
      "            },\n",
      "            \"data_access\": \"open\",\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [\n",
      "          {\n",
      "            \"description\": \"Naming Conventions\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html\",\n",
      "              \"metadata_id_type\": \"HTTP-URI\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, access is public and open to everyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"restrictions\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"No restrictions, data and source code can be used by anyone.\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"third_party_usability\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"technical_resource\": [\n",
      "          {\n",
      "            \"description\": \"The data can be downloaded either from Github directly (single files or zip) or can be downloaded with git.\\n\\nThe input data files are stored as .csv and .tsv files and need no additional software. \\n\\nThe produced data are .png images and an image viewer is needed to open them.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"software_tools\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"All the data used and produced is based on non-restricted or proprietary data formats (e.g. .csv, .tsv, png, python, jupyter, git).\\n\\nThere is no domain-specific vocabulary to take in consideration.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"interoperability_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Standard vocabulary is used, no mapping required.\",\n",
      "            \"technical_resource_id\": {\n",
      "              \"technical_resource_id\": \"vocabulary_standards\",\n",
      "              \"technical_resource_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"keyword\": \"generated\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"time_corr\",\n",
      "          \"dataset_id_type\": \"custom\"\n",
      "        },\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"preservation_statement\": \"Since the data is stored in a public Github repository, no additional cost has to be covered.\",\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"cost\": [\n",
      "      {\n",
      "        \"title\": \"Costs for making your data FAIR\",\n",
      "        \"description\": \"Since the data is stored in a public Github repository, no additional cost has to be covered.\"\n",
      "      }\n",
      "    ],\n",
      "    \"dm_staff\": [\n",
      "      {\n",
      "        \"name\": \"Martin Pichler\",\n",
      "        \"mbox\": \"mpichler.dev@gmail.com\",\n",
      "        \"staff_id\": {\n",
      "          \"staff_id\": \"https://orcid.org/0000-0001-5305-9063\",\n",
      "          \"staff_id_type\": \"HTTP-ORCID\"\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"ethical_issues_description\": \"No ethical issues exist\",\n",
      "    \"ethical_issues_exist\": \"no\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(horizon_parser.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
