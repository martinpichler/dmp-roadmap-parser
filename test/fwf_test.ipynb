{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import datefinder\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class FWFParser():\n",
    "    \n",
    "    def __init__(self, dmp_title, dmp_description, dmp_created, dmp_modified, dmp_id, pi_name, pi_mail, pi_orcid):\n",
    "        self.setup_dmp(dmp_title, dmp_description, dmp_created, dmp_modified, dmp_id, pi_name, pi_mail, pi_orcid)\n",
    "    \n",
    "    def setup_dmp(self, dmp_title, dmp_description, dmp_created, dmp_modified, dmp_id, pi_name, pi_mail, pi_orcid):\n",
    "        self.dmp = {\n",
    "            \"dmp\":{\n",
    "                \"title\": dmp_title,\n",
    "                \"description\":\"Abstract::\"+dmp_description,\n",
    "                \"created\":dmp_created,\n",
    "                \"modified\":dmp_modified,\n",
    "                \"dmp_id\": {\n",
    "                    \"dmp_id\": dmp_id,\n",
    "                    \"dmp_id_type\": \"HTTP-DOI\"\n",
    "                },\n",
    "                \"contact\":{\n",
    "                    \"name\": pi_name,\n",
    "                    \"mail\": pi_mail,\n",
    "                    \"contact_id\": {\n",
    "                        \"contact_id\": pi_orcid,\n",
    "                        \"contact_id_type\": \"HTTP-ORCID\"\n",
    "                    }\n",
    "                },\n",
    "                \"project\": {}\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def __split_text_based_on_title(self, text):\n",
    "        rep = {}\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            title = ds[\"title\"].lower()\n",
    "            rep[title]=\";\"+title\n",
    "\n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text.lower()).split(\";\")\n",
    "        return text\n",
    "    \n",
    "    def __split_text_based_on_fair(self, text):\n",
    "        rep = [\"findable\", \"accessible\"]\n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text.lower()).split(\";\")\n",
    "        return text\n",
    "    \n",
    "    def parse_question_1_1(self, text):\n",
    "        rep = {\"Title:\": \";Title:\", \"Description:\": \";Description:\",\"Type:\": \";Type:\",\"Format:\": \";Format:\", \"Source:\":\";Source:\", \"Size\":\";Size:\"} # define desired replacements here\n",
    "        order = ['b', 'kb', 'mb', 'gb', 'tb', 'pb']\n",
    "        rep_lower = {}\n",
    "        for k, v in rep.items():\n",
    "            rep_lower[k.lower()]=v\n",
    "        rep.update(rep_lower)    \n",
    "\n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        text = pattern.sub(lambda m: rep[re.escape(m.group(0))], q1_3_test_1)\n",
    "\n",
    "        datasets = []\n",
    "        current_dataset = None\n",
    "        current_format = None\n",
    "        current_size = None\n",
    "        for line in text.split(\";\"):\n",
    "            line = line.replace(\"\\n\",\"\")\n",
    "            if line.startswith(\"Title:\"):\n",
    "\n",
    "                line = line[7:] if line[6:].startswith(\" \") else line[6:]\n",
    "\n",
    "                if current_dataset != None:\n",
    "                    if \"distribution\" not in current_dataset:\n",
    "                        current_dataset[\"distribution\"] = []\n",
    "                        current_dataset[\"distribution\"].append({\"title\":\"Project\"})\n",
    "                    else:\n",
    "                        if current_format != None:\n",
    "                            for ds in current_dataset[\"distribution\"]:\n",
    "                                ds[\"format\"] = current_format\n",
    "                            current_format = None\n",
    "                        if current_size != None:\n",
    "                            for ds in current_dataset[\"distribution\"]:\n",
    "                                ds[\"byte_size\"] = current_size\n",
    "                            current_size = None\n",
    "                    current_dataset[\"metadata\"] = []\n",
    "                    current_dataset[\"technical_resource\"] = []\n",
    "                    datasets.append(current_dataset)\n",
    "                current_dataset = {\"title\":line}\n",
    "\n",
    "            if line.startswith(\"Description:\"):\n",
    "                if current_dataset != None:\n",
    "                    line = line[13:] if line[12:].startswith(\" \") else line[12:]\n",
    "                    current_dataset[\"description\"]=line\n",
    "\n",
    "            if line.startswith(\"Type:\"):\n",
    "                if current_dataset != None:\n",
    "                    line = line[6:] if line[5:].startswith(\" \") else line[5:]\n",
    "                    current_dataset[\"type\"]=line\n",
    "\n",
    "            if line.startswith(\"Format:\"):\n",
    "                if current_dataset != None:\n",
    "                    line = line[8:] if line[7:].startswith(\" \") else line[7:]\n",
    "                    current_format = line\n",
    "                    \n",
    "            if line.startswith(\"Size:\"):\n",
    "                if current_dataset != None:\n",
    "                    line = line[8:] if line[7:].startswith(\" \") else line[7:]\n",
    "                    regex1  = re.compile(r'(\\d+(?:\\.\\d+)?)\\s*([kmgtp]?b)', re.IGNORECASE)\n",
    "                    regex2 = re.compile(r'(\\d+(?:\\.\\d+)?)',  re.IGNORECASE)\n",
    "                    size1 = regex1.findall(line)\n",
    "                    size2 = regex2.findall(line)\n",
    "                    if len(size1) >= 1:\n",
    "                        size1 = size1[0]\n",
    "                        size1 = int(float(size1[0]) * (1024**order.index(size1[1].lower())))                    \n",
    "                        current_size = size1\n",
    "                    elif len(size2) >= 1:\n",
    "                        current_size = size2\n",
    "\n",
    "            if line.startswith(\"Source:\"):\n",
    "                if current_dataset != None:\n",
    "                    line = line[8:] if line[7:].startswith(\" \") else line[7:]   \n",
    "                    if line.lower() == \"input\":\n",
    "                        current_dataset[\"distribution\"] = []\n",
    "                        current_dataset[\"distribution\"].append({\"title\":\"Origin\"})\n",
    "                        current_dataset[\"distribution\"].append({\"title\":\"Project\"})\n",
    "                    elif line.lower() == \"produced\":\n",
    "                        current_dataset[\"distribution\"] = []\n",
    "                        current_dataset[\"distribution\"].append({\"title\":\"Project\"})\n",
    "\n",
    "        if current_dataset != None:\n",
    "            if \"distribution\" not in current_dataset:\n",
    "                current_dataset[\"distribution\"] = []\n",
    "                current_dataset[\"distribution\"].append({\"title\":\"Project\"})\n",
    "            else:\n",
    "                if current_format != None:\n",
    "                    for ds in current_dataset[\"distribution\"]:\n",
    "                        ds[\"format\"] = current_format\n",
    "                    current_format = None\n",
    "                if current_size != None:\n",
    "                    for ds in current_dataset[\"distribution\"]:\n",
    "                        ds[\"byte_size\"] = current_size\n",
    "                    current_size = None\n",
    "            current_dataset[\"metadata\"] = []\n",
    "            current_dataset[\"technical_resource\"] = []\n",
    "            datasets.append(current_dataset)\n",
    "        \n",
    "        self.dmp[\"dmp\"][\"dataset\"]=datasets\n",
    "        return datasets\n",
    "    \n",
    "    def parse_question_1_1_1(self, text):\n",
    "        ret_val = []        \n",
    "        keywords = [\"Endevor\", \"AccuRev SCM\", \"ClearCase\", \"Dimensions CM\", \"IC Manage\", \"PTC Integrity\", \"PVCS\", \"Rational Team Concert\", \"SCM Anywhere\", \"StarTeam\", \"Subversion\", \"SVN\", \"Surround SCM\", \"Vault\", \"Perforce Helix Core\", \"Synergy\", \"Plastic SCM\", \"Azure DevOps\", \"BitKeeper\", \"Code Co-op\", \"darcs\", \"Fossil\", \"Git\", \"Mercurial\", \"Monotone\", \"Pijul\", \"GNU Bazaar\", \"Revision Control System\", \"Source Code Control System\", \"Team Foundation Server\"]\n",
    "        text = text.lower()\n",
    "        for keyword in keywords:\n",
    "            keyword = keyword.lower()\n",
    "            if keyword in text:\n",
    "                for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                    for dist in ds[\"distribution\"]:\n",
    "                        if dist[\"title\"] == \"Project\":\n",
    "                            dist[\"host\"] = {\n",
    "                                \"title\": keyword,\n",
    "                                \"supports_versioning\": \"yes\"\n",
    "                            }\n",
    "                            ret_val.append({\n",
    "                                \"dataset\":ds[\"title\"],\n",
    "                                \"supports_versioning\": \"yes\",\n",
    "                                \"title\": keyword\n",
    "                            })\n",
    "        return ret_val\n",
    "\n",
    "    \n",
    "    def parse_question_2_1(self, text):\n",
    "        ret_val = []       \n",
    "        text = self.__split_text_based_on_title(text)\n",
    "\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            for line in text:\n",
    "                if line.startswith(ds[\"title\"].lower()):   \n",
    "                    \n",
    "                    url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', line)\n",
    "                    filename = re.findall('[\\w\\d\\-.\\/:]+\\.\\w+', line)\n",
    "                    if len(url) >= 1:\n",
    "                        url = url[0] \n",
    "                        if url.endswith(\".\") or url.endswith(\",\")  or url.endswith(\")\"):\n",
    "                            url = url[:-1]\n",
    "                        ds[\"metadata\"].append({\n",
    "                            \"description\":\"Dataset Metadata\",\n",
    "                            \"language\":\"en\",\n",
    "                            \"metadata_id\": {\n",
    "                                \"metadata_id\": url,\n",
    "                                \"metadata_id_type\": \"HTTP-URI\"\n",
    "                            }\n",
    "                        })\n",
    "                        ret_val.append({\n",
    "                            \"dataset\": ds[\"title\"],\n",
    "                            \"description\":\"Dataset Metadata\",\n",
    "                            \"language\":\"en\",\n",
    "                            \"metadata_id\": {\n",
    "                                \"metadata_id\": url,\n",
    "                                \"metadata_id_type\": \"HTTP-URI\"\n",
    "                            }\n",
    "                        })\n",
    "                    if len(filename) >= 1:\n",
    "                        new_names = []\n",
    "                        for f in filename:\n",
    "                            if not f.startswith(\"http\"):\n",
    "                                new_names.append(f)\n",
    "                        filename = new_names[0] \n",
    "                        ds[\"metadata\"].append({\n",
    "                            \"description\":\"Dataset Metadata\",\n",
    "                            \"language\":\"en\",\n",
    "                            \"metadata_id\": {\n",
    "                                \"metadata_id\": filename,\n",
    "                                \"metadata_id_type\": \"custom\"\n",
    "                            }\n",
    "                        })\n",
    "                        ret_val.append({\n",
    "                            \"dataset\": ds[\"title\"],\n",
    "                            \"description\":\"Dataset Metadata\",\n",
    "                            \"language\":\"en\",\n",
    "                            \"metadata_id\": {\n",
    "                                \"metadata_id\": filename,\n",
    "                                \"metadata_id_type\": \"custom\"\n",
    "                            }\n",
    "                        })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_2(self, text):\n",
    "        ret_val = []\n",
    "        urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "        if len(urls) >= 1:\n",
    "            url = urls[0]\n",
    "            if url.endswith(\".\") or url.endswith(\",\") or url.endswith(\")\"):\n",
    "                url = url[:-1]\n",
    "            for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "                for dist in ds[\"distribution\"]:\n",
    "                    if dist[\"title\"] == \"Project\":\n",
    "                        dist[\"access_url\"] = url\n",
    "                        tld = re.findall('[^.]*\\.[^.]{2,3}(?:\\.[^.]{2,3})?$', url)\n",
    "                        tld = urlparse(url).netloc\n",
    "                        dist[\"host\"][\"title\"] = tld\n",
    "                        ret_val.append({\"access_url\": url, \"host\":{\"title\":tld}})\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_2_3(self, text):\n",
    "        ret_val = {}\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"data_quality_assurance\"] = text\n",
    "            ret_val[ds[\"title\"]] = text\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_3_1(self, text):\n",
    "        ret_val = {}\n",
    "        rep = {}\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            \n",
    "            # check if \"input\"\n",
    "            bIsInput = False\n",
    "            for dist in ds[\"distribution\"]:\n",
    "                if dist[\"title\"] == \"Origin\":\n",
    "                    bIsInput = True\n",
    "                    break\n",
    "                    \n",
    "            \n",
    "            if bIsInput:\n",
    "                title = ds[\"title\"].lower()\n",
    "                rep[title]=\";\"+title\n",
    "\n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text.lower()).split(\";\")\n",
    "\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ret_val[ds[\"title\"]] = []\n",
    "            for dist in ds[\"distribution\"]:\n",
    "                if dist[\"title\"] == \"Origin\":\n",
    "                    for line in text:\n",
    "                        if line.startswith(ds[\"title\"].lower()):\n",
    "                            url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', line)\n",
    "                            if len(url) >= 1:\n",
    "                                url = url[0]\n",
    "                                if url.endswith(\".\") or url.endswith(\",\") or url.endswith(\")\"):\n",
    "                                    url = url[:-1]\n",
    "                                ds[\"dataset_id\"] = {\n",
    "                                    \"dataset_id\": url,\n",
    "                                    \"dataset_id_type\": \"HTTP-URI\"\n",
    "                                }\n",
    "                                dist[\"access_url\"]=url\n",
    "                                ret_val[ds[\"title\"]].append({\n",
    "                                    \"dataset_id\": url,\n",
    "                                    \"dataset_id_type\": \"HTTP-URI\",\n",
    "                                    \"access_url\": url\n",
    "                                })\n",
    "                            else:\n",
    "                                ds[\"dataset_id\"] = {\n",
    "                                    \"dataset_id\": ds[\"title\"],\n",
    "                                    \"dataset_id_type\": \"custom\"\n",
    "                                }\n",
    "                                ret_val[ds[\"title\"]].append({\n",
    "                                    \"dataset_id\": ds[\"title\"],\n",
    "                                    \"dataset_id_type\": \"custom\"\n",
    "                                })\n",
    "                            break\n",
    "                else:\n",
    "                    if \"dataset_id\" not in ds:\n",
    "                        ds[\"dataset_id\"] = {\n",
    "                            \"dataset_id\": ds[\"title\"],\n",
    "                            \"dataset_id_type\": \"custom\"\n",
    "                        }\n",
    "                        ret_val[ds[\"title\"]].append({\n",
    "                            \"dataset_id\": ds[\"title\"],\n",
    "                            \"dataset_id_type\": \"custom\"\n",
    "                        })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_3_2(self, text):\n",
    "        ret_val = []\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"security_and_privacy\"] = [{\n",
    "                \"title\": \"Data Security\",\n",
    "                \"text\": text\n",
    "            }]\n",
    "            ret_val.append({\n",
    "                \"dataset\": ds[\"title\"],\n",
    "                \"title\": \"Data Security\",\n",
    "                \"text\": text\n",
    "            })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_4_1(self, text):\n",
    "        ret_val = []\n",
    "        for ds in self.dmp[\"dmp\"][\"dataset\"]:\n",
    "            ds[\"security_and_privacy\"] = [{\n",
    "                \"title\": \"Data Security\",\n",
    "                \"text\": text\n",
    "            }]\n",
    "            ret_val.append({\n",
    "                \"dataset\": ds[\"title\"],\n",
    "                \"title\": \"Data Security\",\n",
    "                \"text\": text\n",
    "            })\n",
    "        return ret_val\n",
    "    \n",
    "    def parse_question_4_2(self, text):\n",
    "        ret_val = {}\n",
    "        \n",
    "        self.dmp[\"dmp\"][\"ethical_issues_description\"] = text\n",
    "        ret_val[\"ethical_issues_description\"] = text\n",
    "        \n",
    "        self.dmp[\"dmp\"][\"ethical_issues_exist\"] = \"no\"\n",
    "        ret_val[\"ethical_issues_exist\"] = \"no\"\n",
    "        \n",
    "        url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "        if len(url)>=1:\n",
    "            url = url[0]\n",
    "            if url.endswith(\".\") or url.endswith(\",\") or url.endswith(\")\"):\n",
    "                url = url[:-1]\n",
    "            self.dmp[\"dmp\"][\"ethical_issues_report\"] = url\n",
    "            ret_val[\"ethical_issues_report\"] = url\n",
    "            \n",
    "            self.dmp[\"dmp\"][\"ethical_issues_exist\"] = \"yes\"\n",
    "            ret_val[\"ethical_issues_exist\"] = \"yes\"\n",
    "            \n",
    "        return ret_val\n",
    "\n",
    "    def generate(self):\n",
    "        return json.dumps(self.dmp, indent=2, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test FWFParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmp_title = \"Parser Test\"\n",
    "dmp_description = \"DMP Abstract is located here\"\n",
    "dmp_created = \"2017-01-01\" \n",
    "dmp_modified = \"2018-01-01\"\n",
    "dmp_id = \"http://validorcid.com/12345\"\n",
    "pi_name = \"Martin Pichler\"\n",
    "pi_mail = \"pichler.martin@outlook.at\"\n",
    "pi_orcid = \"https://orcid.org/0000-0001-5305-9063\"\n",
    "\n",
    "fwf_parser = FWFParser(dmp_title, dmp_description, dmp_created, dmp_modified, dmp_id, pi_name, pi_mail, pi_orcid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'supports_versioning': 'yes',\n",
       "  'title': 'git'},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'supports_versioning': 'yes',\n",
       "  'title': 'git'},\n",
       " {'dataset': 'scatter', 'supports_versioning': 'yes', 'title': 'git'},\n",
       " {'dataset': 'time_change', 'supports_versioning': 'yes', 'title': 'git'},\n",
       " {'dataset': 'time_corr', 'supports_versioning': 'yes', 'title': 'git'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_1_test_1 = \"\"\"Title: Ehescheidungen (Statistik Austria)\n",
    "Description: Divorce statistic of austria\n",
    "Type: Dataset\n",
    "Format: csv\n",
    "Source: Input\n",
    "Size: 1KB\n",
    "\n",
    "Title: Divorces by duration of marriage (Eurostat)\n",
    "Description: Divorce statistic of the EU\n",
    "Type: Dataset\n",
    "Format: tsv\n",
    "Source: Input\n",
    "Size: 297KB\n",
    "\n",
    "Title: scatter\n",
    "Description: Scatterplot\n",
    "Type: Image\n",
    "Format: png\n",
    "Source: Produced\n",
    "Size: 15KB\n",
    "\n",
    "Title: time_change\n",
    "Description: Time Change Plot\n",
    "Type: Image\n",
    "Format: png\n",
    "Source: Produced\n",
    "Size: 30KB\n",
    "\n",
    "Title: time_corr\n",
    "Description: Time Correlation Plot\n",
    "Type: Image\n",
    "Format: png\n",
    "Source: Produced\n",
    "Size: 15KB\n",
    "\n",
    "The original release was versioned as v1.0.0. Every further release however will follow a date based versioning pattern <year>.<month>.<day>.<sequence_within_day> (e.g. 2019.04.19.01).\n",
    "\n",
    "Since the project is hosted as a git repository, keeping track of changes to the data is handled automatically.\n",
    "\"\"\"\n",
    "\n",
    "fwf_parser.parse_question_1_1(q1_1_test_1)\n",
    "fwf_parser.parse_question_1_1_1(q1_1_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'Dataset Metadata',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c',\n",
       "   'metadata_id_type': 'HTTP-URI'}},\n",
       " {'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'description': 'Dataset Metadata',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'divorce_analysis.ipynb',\n",
       "   'metadata_id_type': 'custom'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'Dataset Metadata',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'http://data.europa.eu/euodp/en/data/dataset/brjas74zddipeu7mnkhmia',\n",
       "   'metadata_id_type': 'HTTP-URI'}},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'description': 'Dataset Metadata',\n",
       "  'language': 'en',\n",
       "  'metadata_id': {'metadata_id': 'divorce_analysis.ipynb',\n",
       "   'metadata_id_type': 'custom'}}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_1_test_1 = \"The metadata description for Ehescheidungen (Statistik Austria) can be found in the jupyter notebook file divorce_analysis.ipynb or can be accessed online at https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c. The metadata description for Divorces by duration of marriage (Eurostat) is stored in the same file \\\"divorce_analysis.ipynb\\\" or online at http://data.europa.eu/euodp/en/data/dataset/bRJAS74ZDdIpeU7mnKhMiA.\"\n",
    "\n",
    "fwf_parser.parse_question_2_1(q2_1_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}},\n",
       " {'access_url': 'https://github.com/martinpichler/data_stewardship_ex1)',\n",
       "  'host': {'title': 'github.com'}}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_2_test_1 = \"The data can be accessed through Github (https://github.com/martinpichler/data_stewardship_ex1). Documentation is available there.\"\n",
    "\n",
    "fwf_parser.parse_question_2_2(q2_2_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ehescheidungen (Statistik Austria)': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.',\n",
       " 'Divorces by duration of marriage (Eurostat)': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.',\n",
       " 'scatter': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.',\n",
       " 'time_change': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.',\n",
       " 'time_corr': 'The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_3_test_1 = \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\"\n",
    "\n",
    "fwf_parser.parse_question_2_3(q2_3_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ehescheidungen (Statistik Austria)': [{'dataset_id': 'https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c',\n",
       "   'dataset_id_type': 'HTTP-URI',\n",
       "   'access_url': 'https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c'}],\n",
       " 'Divorces by duration of marriage (Eurostat)': [{'dataset_id': 'https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur',\n",
       "   'dataset_id_type': 'HTTP-URI',\n",
       "   'access_url': 'https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur'}],\n",
       " 'scatter': [{'dataset_id': 'scatter', 'dataset_id_type': 'custom'}],\n",
       " 'time_change': [{'dataset_id': 'time_change', 'dataset_id_type': 'custom'}],\n",
       " 'time_corr': [{'dataset_id': 'time_corr', 'dataset_id_type': 'custom'}]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_1_test_1 = \"\"\"Ehescheidungen (Statistik Austria) was downloaded from https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c.\n",
    "\n",
    "Divorces by duration of marriage (Eurostat) was downloaded from https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur.\n",
    "\n",
    "scatter was produced during research.\n",
    "\n",
    "time_change was produced during research.\n",
    "\n",
    "time_corr was produced during research.\"\"\"\n",
    "\n",
    "fwf_parser.parse_question_3_1(q3_1_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'},\n",
       " {'dataset': 'scatter',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'},\n",
       " {'dataset': 'time_change',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'},\n",
       " {'dataset': 'time_corr',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.'}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_2_test_1 = \"Data is stored in a git repository on Github and can only be modified by the owner or an administrator. If data is lost locally, the original data can be downloaded from the Github repository. No sensitive data is stored and thus the repository does not need to be addressed.\"\n",
    "\n",
    "fwf_parser.parse_question_3_2(q3_2_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'Ehescheidungen (Statistik Austria)',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'No legal aspects to mention'},\n",
       " {'dataset': 'Divorces by duration of marriage (Eurostat)',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'No legal aspects to mention'},\n",
       " {'dataset': 'scatter',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'No legal aspects to mention'},\n",
       " {'dataset': 'time_change',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'No legal aspects to mention'},\n",
       " {'dataset': 'time_corr',\n",
       "  'title': 'Data Security',\n",
       "  'text': 'No legal aspects to mention'}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q4_1_test_1 = \"No legal aspects to mention\"\n",
    "\n",
    "fwf_parser.parse_question_4_1(q4_1_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ethical_issues_description': 'No ethical issues exist',\n",
       " 'ethical_issues_exist': 'no'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q4_2_test_1 = \"No ethical issues exist\"\n",
    "\n",
    "fwf_parser.parse_question_4_2(q4_2_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dmp\": {\n",
      "    \"title\": \"Parser Test\",\n",
      "    \"description\": \"Abstract::DMP Abstract is located here\",\n",
      "    \"created\": \"2017-01-01\",\n",
      "    \"modified\": \"2018-01-01\",\n",
      "    \"dmp_id\": {\n",
      "      \"dmp_id\": \"http://validorcid.com/12345\",\n",
      "      \"dmp_id_type\": \"HTTP-DOI\"\n",
      "    },\n",
      "    \"contact\": {\n",
      "      \"name\": \"Martin Pichler\",\n",
      "      \"mail\": \"pichler.martin@outlook.at\",\n",
      "      \"contact_id\": {\n",
      "        \"contact_id\": \"https://orcid.org/0000-0001-5305-9063\",\n",
      "        \"contact_id_type\": \"HTTP-ORCID\"\n",
      "      }\n",
      "    },\n",
      "    \"project\": {},\n",
      "    \"dataset\": [\n",
      "      {\n",
      "        \"title\": \"Ehescheidungen (Statistik Austria)\",\n",
      "        \"description\": \"Divorce statistic of austria\",\n",
      "        \"type\": \"Dataset\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Origin\",\n",
      "            \"format\": \"csv\",\n",
      "            \"byte_size\": 1024,\n",
      "            \"access_url\": \"https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c\"\n",
      "          },\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"csv\",\n",
      "            \"byte_size\": 1024,\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\"\n",
      "            },\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [\n",
      "          {\n",
      "            \"description\": \"Dataset Metadata\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c\",\n",
      "              \"metadata_id_type\": \"HTTP-URI\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Dataset Metadata\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"divorce_analysis.ipynb\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"technical_resource\": [],\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"https://www.data.gv.at/katalog/dataset/2d8ad82c-4730-3354-9971-9406f2ccf72c\",\n",
      "          \"dataset_id_type\": \"HTTP-URI\"\n",
      "        },\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"No legal aspects to mention\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"Divorces by duration of marriage (Eurostat)\",\n",
      "        \"description\": \"Divorce statistic of the EU\",\n",
      "        \"type\": \"Dataset\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Origin\",\n",
      "            \"format\": \"tsv\",\n",
      "            \"byte_size\": 304128,\n",
      "            \"access_url\": \"https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur\"\n",
      "          },\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"tsv\",\n",
      "            \"byte_size\": 304128,\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\"\n",
      "            },\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [\n",
      "          {\n",
      "            \"description\": \"Dataset Metadata\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"http://data.europa.eu/euodp/en/data/dataset/brjas74zddipeu7mnkhmia\",\n",
      "              \"metadata_id_type\": \"HTTP-URI\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Dataset Metadata\",\n",
      "            \"language\": \"en\",\n",
      "            \"metadata_id\": {\n",
      "              \"metadata_id\": \"divorce_analysis.ipynb\",\n",
      "              \"metadata_id_type\": \"custom\"\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"technical_resource\": [],\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"https://ec.europa.eu/eurostat/web/products-datasets/-/demo_ndivdur\",\n",
      "          \"dataset_id_type\": \"HTTP-URI\"\n",
      "        },\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"No legal aspects to mention\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"scatter\",\n",
      "        \"description\": \"Scatterplot\",\n",
      "        \"type\": \"Image\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"png\",\n",
      "            \"byte_size\": 15360,\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\"\n",
      "            },\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [],\n",
      "        \"technical_resource\": [],\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"scatter\",\n",
      "          \"dataset_id_type\": \"custom\"\n",
      "        },\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"No legal aspects to mention\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"time_change\",\n",
      "        \"description\": \"Time Change Plot\",\n",
      "        \"type\": \"Image\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"png\",\n",
      "            \"byte_size\": 30720,\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\"\n",
      "            },\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [],\n",
      "        \"technical_resource\": [],\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"time_change\",\n",
      "          \"dataset_id_type\": \"custom\"\n",
      "        },\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"No legal aspects to mention\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"time_corr\",\n",
      "        \"description\": \"Time Correlation Plot\",\n",
      "        \"type\": \"Image\",\n",
      "        \"distribution\": [\n",
      "          {\n",
      "            \"title\": \"Project\",\n",
      "            \"format\": \"png\",\n",
      "            \"byte_size\": 15360,\n",
      "            \"host\": {\n",
      "              \"title\": \"github.com\",\n",
      "              \"supports_versioning\": \"yes\"\n",
      "            },\n",
      "            \"access_url\": \"https://github.com/martinpichler/data_stewardship_ex1)\"\n",
      "          }\n",
      "        ],\n",
      "        \"metadata\": [],\n",
      "        \"technical_resource\": [],\n",
      "        \"data_quality_assurance\": \"The project only uses already available data and no new data will be generated in the future. The used data was checked for completeness and correctness.\",\n",
      "        \"dataset_id\": {\n",
      "          \"dataset_id\": \"time_corr\",\n",
      "          \"dataset_id_type\": \"custom\"\n",
      "        },\n",
      "        \"security_and_privacy\": [\n",
      "          {\n",
      "            \"title\": \"Data Security\",\n",
      "            \"text\": \"No legal aspects to mention\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"ethical_issues_description\": \"No ethical issues exist\",\n",
      "    \"ethical_issues_exist\": \"no\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(fwf_parser.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
